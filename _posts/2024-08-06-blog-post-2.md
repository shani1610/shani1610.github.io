---
title: 'Exploring Segmentation Methods'
date: 2024-08-06
permalink: /posts/2024/08/blog-post-2/
tags:
  - deeplearning
---

## Segmantation

Here I will explore 2 popular classic approaches for segmentation and 2 popular deep learning approches for segmantation, Mask RCNN and UNet. 

## Mask RCNN
built upon Faster RCNN 
in parallel to predicting the class and box
offset, Mask R-CNN also outputs a binary mask for each
RoI. The mask branch is a small FCN applied
to each RoI, predicting a segmentation mask in a pixel-topixel manner


we rely on the dedicated classification branch to predict the
class label used to select the output mask.extracting the spatial structure
of masks can be addressed naturally by the pixel-to-pixel
correspondence provided by convolutions.we predict an m × m mask from each RoI
using an FCN [30]. This allows each layer in the mask
branch to maintain the explicit m × m object spatial layout without collapsing it into a vector representation that
lacks spatial dimensions

This pixel-to-pixel behavior requires our RoI features,
which themselves are small feature maps, to be well aligned
to faithfully preserve the explicit per-pixel spatial correspondence. This motivated us to develop the
RoIAlign layer.

during training, we define a multi-task loss on
each sampled RoI as L = Lcls + Lbox + Lmask. 
The mask branch has a Km2
dimensional output for each RoI, which encodes K binary
masks of resolution m × m, one for each of the K classes.

To this we apply a per-pixel sigmoid, and define Lmask as
the average binary cross-entropy loss. 

For an RoI associated
with ground-truth class k, Lmask is only defined on the k-th
mask (other mask outputs do not contribute to the loss).

Our definition of Lmask allows the network to generate
masks for every class without competition among classes;

<img src="/images/segmentation/head_archi.png" alt="drawing" width="200"/>

in the paper they also mentioned that Our framework can easily be extended to human pose
estimation. We model a keypoint’s location as a one-hot
mask, and adopt Mask R-CNN to predict K masks, one for
each of K keypoint types (e.g., left shoulder, right elbow).
This task helps demonstrate the flexibility of Mask R-CNN.

## U-Net


**Metrics**  
Binary Cross-Entropy
Cross-entropy is used to measure the difference between two probability distributions. It is used as a similarity metric to tell how close one distribution of random events are to another, and is used for both classification (in the more general sense) as well as segmentation.

The binary cross-entropy (BCE) loss therefore attempts to measure the differences of information content between the actual and predicted image masks. It is more generally based on the Bernoulli distribution, and works best with equal data-distribution amongst classes. In other terms, image masks with very heavy class imbalance may (such as in finding very small, rare tumors from X-ray images) may not be adequately evaluated by BCE.

This is due to the fact that the BCE treats both positive (1) and negative (0) samples in the image mask equally. Since there may be an unequal distribution of pixels that represent a given object (say, a car from the first image above) and the rest of the image, the BCE loss may not effectively represent the performance of the deep-learning model.

Dice Coefficient
This is a widely-used loss to calculate the similarity between images and is similar to the Intersection-over-Union heuristic. The Dice Coefficient has as such, been adapted to a loss function as the Dice Loss


